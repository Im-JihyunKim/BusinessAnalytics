
# 2022 Business Analytics Chapter 3: Anomaly DetectionğŸ§
### Python Tutorial: Anomaly Detection Using AutoEncoder with Time Series Data
### 2022010558 ê¹€ì§€í˜„ğŸ²

<br/>

## Table of Contents

------------------

# Anomaly Detection: Overview

## Definition of Anomaly(Novel Data)

<p align="center">
    <img src="Anomaly_Detection_Img/What_is_Anomaly.jpg" width="800"/>
</p>

ì´ë²ˆ íŠœí† ë¦¬ì–¼ì€ 'Anomaly Detection(ì´ìƒì¹˜ íƒì§€)'ì— ëŒ€í•œ ì£¼ì œë¡œ ì§„í–‰í•˜ë ¤ í•©ë‹ˆë‹¤. ê·¸ë ‡ë‹¤ë©´ 'ì´ìƒì¹˜(Anomaly, Novel Data)'ë€ ë¬´ì—‡ì¼ê¹Œìš”? ìœ„ ì‚¬ì§„ì„ ë³´ë©´, ì–‘ìƒì€ ë‹¤ë¥´ì§€ë§Œ ëŒ€ë¶€ë¶„ í˜¸ë‘ì´ ê°ì²´ë°–ì— ì—†ëŠ” ìƒí™©ì—ì„œ ë‹¨ í•˜ë‚˜ ìš©ì— ëŒ€í•œ ê°ì²´ê°€ ìˆë‹¤ë©´, ì´ëŠ” ì¼ë°˜ì ì¸ ê°ì²´ë“¤ë³´ë‹¤ëŠ” ì¡°ê¸ˆ ë‹¤ë¥¸ íŠ¹ì´í•œ ê°ì²´ê°€ ë  ê²ƒì…ë‹ˆë‹¤. ì´ì²˜ëŸ¼ __ì¼ë°˜ì ì¸ ë°ì´í„°ì™€ëŠ” ë‹¤ë¥¸ ì¡°ê¸ˆ íŠ¹ì´í•œ ê°ì²´ë¥¼ Anomaly__ ë¼ê³  í•˜ê³ , ì´ë¥¼ ì°¾ì•„ë‚´ëŠ” ê²ƒì´ ì´ìƒì¹˜ íƒì§€ì˜ ëª©ì ì´ ë©ë‹ˆë‹¤.

ë³´ë‹¤ í•™ìˆ ì ìœ¼ë¡œëŠ”, ì•„ë˜ì™€ ê°™ì´ 'ì´ìƒì¹˜(Anomaly, Novel Data)'ë¥¼ 2ê°€ì§€ ê´€ì ì—ì„œ ì •ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.   

1. __ë°ì´í„° ìƒì„± ë©”ì»¤ë‹ˆì¦˜__ ì—ì„œì˜ ê´€ì : ì¼ë°˜ì ì¸ ë°ì´í„°ì™€ëŠ” ë‹¤ë¥¸ ë©”ì»¤ë‹ˆì¦˜ì— ì˜í•´ ë°œìƒí•œ ë°ì´í„°    
"Observations that deviate so much from other observations as to arouse suspicions that they were generated by a different mechanism (Hawkins, 1980)"   

2. __ë°ì´í„° ë¶„í¬ì—ì„œì˜ ë°€ë„__ ì— ëŒ€í•œ ê´€ì : ê°ì²´ë“¤ì´ ë°œìƒí•  ìˆ˜ ìˆëŠ” í™•ë¥  ë°€ë„ê°€ ë‚®ì€ ë°ì´í„°   
â€œInstances that their true probability density is very low (Harmelinget al., 2006)"

<br/>

> __(ì°¸ê³ ) Anomaly vs. Noise__   
> ì´ìƒì¹˜ ë°ì´í„°ëŠ” ë…¸ì´ì¦ˆ ë°ì´í„°ì™€ëŠ” ë‹¤ë¦…ë‹ˆë‹¤. ë…¸ì´ì¦ˆëŠ” ë°ì´í„° ìˆ˜ì§‘ ê³¼ì •ì—ì„œì˜ ë¬´ì‘ìœ„ì„±(Randomness)ì— ê¸°ë°˜í•˜ì—¬ ìì—° ë°œìƒì ìœ¼ë¡œ ë“¤ì–´ê°€ëŠ” ë³€ë™ì„±ì„ ì˜ë¯¸í•˜ë©°, ë”°ë¼ì„œ ë°ì´í„° ë¶„ì„ ì‹œ ì •í™•íˆ ê°€ë ¤ ì§€ì›Œë‚´ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ë°ì´í„°ì— ë…¸ì´ì¦ˆê°€ ë‚´ì¬ë˜ì–´ ìˆë‹¤ëŠ” ê°€ì • í•˜ì— ë¶„ì„ì„ ì§„í–‰í•©ë‹ˆë‹¤.   
>
> ë°˜ë©´ ì´ìƒì¹˜ëŠ” __ë¶„ì„ ê³¼ì •ì—ì„œ ë°˜ë“œì‹œ ì°¾ì•„ë‚´ì•¼ í•˜ëŠ” "í¥ë¯¸ê°€ ìˆëŠ” ê°ì²´"__ ë¼ê³  ì´í•´í•´ì•¼ í•©ë‹ˆë‹¤. ì¼ë°˜ì ì¸ ë°ì´í„°ë¥¼ ìƒì„±í•˜ëŠ” ë©”ì»¤ë‹ˆì¦˜ì„ ìœ„ë°°í•˜ì—¬ ë§Œë“¤ì–´ì§„ ë°ì´í„°ì´ê¸° ë•Œë¬¸ì—, ì´ë¥¼ ë°œê²¬í•˜ì—¬ __XAIì™€ ê°™ì´ ì‚¬í›„ì ì¸ ë¶„ì„ì„ ìˆ˜í–‰í•´ì•¼ í•  í•„ìš”ê°€ ìˆê³ , ê·¸ ê°ì²´ë¥¼ ì°¾ì•„ë‚´ëŠ” ê²ƒ ìì²´ë§Œìœ¼ë¡œë„ ë¶„ì„ì— ë§¤ìš° ë„ì›€ì´ ë˜ê¸° ë•Œë¬¸__ ì…ë‹ˆë‹¤.   

<br/>

ê·¸ë ‡ë‹¤ë©´ ì´ëŸ° ì˜ë¬¸ì´ ë“¤ ìˆ˜ ìˆê² ì£ . ì´ìƒì¹˜ íƒì§€ë¥¼ í•˜ê³  ì‹¶ì„ ë•Œ, ì •ìƒê³¼ ì´ìƒì„ ë¶„ë¥˜í•´ë‚¼ ìˆ˜ ìˆëŠ” Binary Classification ì•Œê³ ë¦¬ì¦˜ì„ ì ìš©í•˜ë©´ ì•ˆ ë˜ëŠ” ê±¸ê¹Œìš”? **ì™œ ìš°ë¦¬ëŠ” Anomaly Detectionì´ë¼ëŠ” ìƒˆë¡œìš´ ë¶„ì•¼ì˜ ì•Œê³ ë¦¬ì¦˜ì„ í•„ìš”ë¡œ í•˜ëŠ” ê±¸ê¹Œìš”?**   

<br/>

## Binary Classification vs. Anomaly Detection
<p align="center">
    <img src="Anomaly_Detection_Img/C_vs_A.jpg" width="800"/>
</p>

ì „í†µì ì¸ ì§€ë„í•™ìŠµ(Supervised Learning) ê´€ì ì—ì„œ Binary Classificationì€ ì£¼ì–´ì§„ ë°ì´í„°ë¥¼ ì˜ êµ¬ë¶„í•˜ëŠ” ë¶„ë¥˜ ê²½ê³„ë©´(Decision Boundary)ì„ ì˜ ì°¾ì•„ë‚´ëŠ” ê²ƒì„ ëª©ì ìœ¼ë¡œ í•©ë‹ˆë‹¤. ìœ„ ê·¸ë¦¼ì˜ ì˜ˆë¥¼ ë´…ì‹œë‹¤. ë§Œì¼ í˜¸ë‘ì´ğŸ¯ê°€ Normalì´ê³  ìš©ğŸ²ì´ Abnormal ë°ì´í„°ë¼ê³  í•œë‹¤ë©´, **Binary Classifier**ëŠ” **ìƒˆë¡œìš´ ë°ì´í„° "A"ë¥¼** ë¬´ì—‡ìœ¼ë¡œ íŒë‹¨í• ê¹Œìš”? Normal Classì˜ ê²½ê³„ë©´ ì•ˆìª½ì— ì†í•´ìˆê¸° ë•Œë¬¸ì— **Normalì´ë¼ê³  íŒë‹¨**í•  ê²ƒì…ë‹ˆë‹¤.    

ì´ë•Œ ìš°ë¦¬ëŠ” ì´ëŸ¬í•œ ì§ˆë¬¸ì„ ë˜ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. **AbnormalğŸ² ê´€ì¸¡ì¹˜ê°€ ì ˆëŒ€ì ìœ¼ë¡œ ì ì€ ìƒí™©ì—ì„œ, í•´ë‹¹ ë°ì´í„°ê°€ Abnormal Classë¥¼ ëŒ€í‘œí•  ìˆ˜ ìˆëŠ”ê°€?"** ì— ëŒ€í•´ ë§ì…ë‹ˆë‹¤. 
ì™œëƒí•˜ë©´ ì ì€ ê´€ì¸¡ì¹˜ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒì„±ëœ ë¶„ë¥˜ ê²½ê³„ë©´ì„ ì˜¨ì „íˆ ì‹ ë¢°í•  ìˆ˜ ì—†ê¸° ë•Œë¬¸ì´ì£ . ìƒê°í•´ë³´ë‹ˆ ìƒˆë¡œìš´ ë°ì´í„° "A"ëŠ” 'Normal'ì´ë¼ê³  íŒë‹¨í•˜ê¸°ì—ëŠ” ë‹¤ë¥¸ ì •ìƒ ê´€ì¸¡ì¹˜ë“¤(ğŸ¯)ê³¼ëŠ” Feature Space ìƒì˜ ê±°ë¦¬ê°€ ê½¤ ë¨¼ ê²ƒì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  
 
ë°”ë¡œ ì´ëŸ¬í•œ ë¬¸ì œë¥¼ ë°”íƒ•ìœ¼ë¡œ, Anomaly Detectionì€ **Normal ë°ì´í„°ëŠ” ì¶©ë¶„íˆ ë§ìœ¼ë‹ˆ, "ì •ìƒ"ì´ë€ ë¬´ì—‡ì¸ê°€ë¥¼ ì •ì˜í•˜ì—¬ ì´ì— í¬í•¨ë˜ì§€ ì•ŠëŠ” ê²ƒì„ ê±¸ëŸ¬ë‚´ë³´ì**ëŠ” ì•„ì´ë””ì–´ì—ì„œ ì¶œë°œí•˜ê²Œ ë©ë‹ˆë‹¤. ì´ëŸ¬í•œ ê´€ì ì—ì„œ **ìƒˆë¡œìš´ ë°ì´í„° "A"** ëŠ” Anomaly Detectionì˜ ê´€ì ì—ì„œëŠ” **Normalì´ ì•„ë‹Œ ê²ƒ**ìœ¼ë¡œ ì¬ì •ì˜ë˜ê² ì£ .   

> **(ì°¸ê³ )**   
> Normalì´ ì•„ë‹ˆë¼ê³  í•´ì„œ ë°ì´í„°ê°€ ë°˜ë“œì‹œ "Abnormal"ì¸ ê²ƒì€ ì•„ë‹™ë‹ˆë‹¤. í•˜ì§€ë§Œ í˜„ ê´€ì¸¡ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë³´ì•˜ì„ ë•Œ í•´ë‹¹ ë°ì´í„°ëŠ” ìš°ë¦¬ê°€ ê·œì •í•œ "Normal"ì´ë¼ í•˜ê¸°ì—ëŠ” ì–´ë ¤ì›€ì´ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ì ‘ê·¼ë²•ì´ ìœ íš¨í•œ ì´ìœ ëŠ” "Abnormal"ì˜ ì¢…ë¥˜ê°€ 2ê°€ì§€ì¼ ë•Œì…ë‹ˆë‹¤. ê°€ìš©í•  ìˆ˜ ìˆëŠ” ë¶ˆëŸ‰ ê´€ì¸¡ì¹˜ê°€ í•˜ë‚˜ì˜ ìœ í˜•(ì´ë¥¼í…Œë©´ ğŸ²)ë°–ì— ì—†ëŠ” ìƒí™©ì—ì„œ, í•œ ë²ˆë„ ê´€ì¸¡ë˜ì§€ ëª»í–ˆë˜ ìƒˆë¡œìš´ ë¶ˆëŸ‰ ìœ í˜•(ì´ë¥¼í…Œë©´ ğŸ¦)ì„ ë°œê²¬í•  ìˆ˜ ìˆë‹¤ëŠ” ì´ì ì„ ê°€ì§€ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.
> 
> ì´ì²˜ëŸ¼ Classificationì€ ë°ì´í„°ë¥¼ ë°˜ë“œì‹œ ì£¼ì–´ì§„ ë²”ì£¼ ì¤‘ í•˜ë‚˜ë¡œ í• ë‹¹í•˜ì§€ë§Œ, Anomaly Detectionì€ ì •ìƒì˜ Boundaryë¥¼ ì •í•˜ê³  'ì •ìƒ' 'ì •ìƒì´ ì•„ë‹˜'ìœ¼ë¡œ ë³´ë‹¤ ê´‘ë²”ìœ„í•œ ë¶„ë¥˜ê°€ ê°€ëŠ¥í•˜ë‹¤ëŠ” ì¸¡ë©´ì—ì„œ ë‘˜ì€ ì°¨ì´ë¥¼ ê°€ì§‘ë‹ˆë‹¤. ì¦‰, Anomaly Detectionì€ ì¼ë°˜ì ì¸ ë°ì´í„°ì˜ ë²”ì£¼ì™€ í™•ì—°íˆ êµ¬ë¶„ë˜ëŠ” ë‹¤ë¥¸ ì–‘ìƒì˜ ë°ì´í„°ë¥¼ ì°¾ëŠ” ê²ƒì´ì£ . ì´ëŸ¬í•œ ê´€ì ì—ì„œ Anomaly Detectionì„ í†µí•´ ì°¾ì•„ë‚¸ ë°ì´í„°ëŠ” ë¶ˆëŸ‰, ì˜¤ë¥˜, ì•…ì„±ì½”ë“œ, ê°€ì§œ ë°ì´í„°ì¼ ìˆ˜ë„ ìˆì§€ë§Œ, ì˜ˆì™¸, ìƒˆë¡œìš´ íŒ¨í„´ ë“±ì˜ ë°ì´í„°ì¼ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.

<br/>

## Assumption of Anomaly Detection
ì´ìƒì¹˜ ë°ì´í„°ì˜ ê¸°ë³¸ ê°€ì •ì€ **ì •ìƒ ë°ì´í„°ê°€ ì •ìƒì´ ì•„ë‹Œ ë°ì´í„°ë³´ë‹¤ í›¨ì”¬ ë” ë§ë‹¤**(There are considerably more "normal" observations than abnormal observations in the data)ì…ë‹ˆë‹¤. ê·¸ë¦¬ê³  ëª¨ë¸ë§ ì‹œì—ëŠ” **ì˜¤ë¡œì§€ ì •ìƒ ë°ì´í„°ë§Œì„ í™œìš©í•˜ì—¬ ëª¨ë¸ì„ í•™ìŠµ**ì‹œí‚¨ í›„, ì •ìƒ ë²”ìœ„ë¥¼ ì •ì˜í•˜ì—¬ ì´ìƒì„ íƒì§€í•´ë‚¸ë‹¤ëŠ” ê°€ì •ì„ ê¸°ì €ë¡œ í™œìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤.   

<br/>

-------

# Dive into Anomaly Detection Using AutoEncoder with Time Series Data
ì´ëŸ¬í•œ ì ì„ ë°”íƒ•ìœ¼ë¡œ, ë³¸ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” Anomaly Detectionì— ëŒ€í•´ì„œ, ê·¸ ì¤‘ì—ì„œë„ ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ ë°”íƒ•ìœ¼ë¡œ ìˆ˜í–‰ë˜ëŠ” **AutoEncoder Based Anomaly Detection**ì— ëŒ€í•œ ê°„ëµí•œ ì†Œê°œ ë° í™œìš© ë°©ì•ˆì— ëŒ€í•´ ì†Œê°œí•´ë³´ê³ ì í•©ë‹ˆë‹¤. ì´ë•Œ **ë”¥ëŸ¬ë‹ ê¸°ë²•ì„ í™œìš©í•œ ëª¨ë¸ ê¸°ë°˜ì˜ Anomaly Detectionì„ ì†Œê°œí•˜ëŠ” ì´ìœ ëŠ”, ë°ì´í„°ê°€ ë‚´í¬í•˜ëŠ” ì •ë³´ë¥¼ ìµœëŒ€í•œ í™œìš©í•˜ëŠ” ë™ì‹œì— êµ¬ì¡°ë¥¼ ìœ ì—°í•˜ê²Œ ë°”ê¾¸ì–´ê°€ë©° ëª¨ë¸ ì„±ëŠ¥ì„ ë†’ì¼ ìˆ˜ ìˆëŠ” ì¥ì ì„ ê°€ì§€ê¸° ë•Œë¬¸**ì…ë‹ˆë‹¤. ë”°ë¼ì„œ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¬ ë§Œí¼ì˜ ì¶©ë¶„í•œ ë°ì´í„°ê°€ ìˆë‹¤ë©´ ë³¸ íŠœí† ë¦¬ì–¼ì„ í†µí•´ ë”¥ëŸ¬ë‹, ê·¸ ì¤‘ì—ì„œë„ AutoEncoderë¥¼ ì´ìš©í•œ Anomaly Detectionì˜ ê¸°ë³¸ì„ ì•Œì•„ê°ˆ ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤.

íŠ¹íˆ ë³¸ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” **ì‹œê³„ì—´ ë°ì´í„°ì— ìˆì–´ ì´ìƒ íƒì§€ì— ëŒ€í•œ íŠœí† ë¦¬ì–¼**ì„ ì‘ì„±í•˜ê³ ì í•˜ë©°, í™œìš©í•˜ê³ ì í•˜ëŠ” ë°ì´í„°ëŠ” **Real-World Time Series Dataset ì¤‘ Electrocardiogram(ECG) ì‹¬ì „ë„ ë°ì´í„°ì…‹**ì…ë‹ˆë‹¤. 

## AutoEncoder
<p align="center">
    <img src="Anomaly_Detection_Img/AE.png" width="800"/>
</p>

AutoEncoderëŠ” í†µìƒì ìœ¼ë¡œ ìœ„ì™€ ê°™ì€ êµ¬ì¡°ë¥¼ ê°€ì§€ëŠ” ëª¨ë¸ë¡œ, **ì…ë ¥ê³¼ ì¶œë ¥ì´ ë™ì¼í•œ ì¸ê³µ ì‹ ê²½ë§ êµ¬ì¡°**ë¥¼ ë°”íƒ•ìœ¼ë¡œ **ì…ë ¥ìœ¼ë¡œ ë°›ì€ ë°ì´í„°(x)ë¥¼ ì¶œë ¥ìœ¼ë¡œ ìµœëŒ€í•œ ê°€ê¹ê²Œ ì¬êµ¬ì¶•(x')í•˜ëŠ” ê²ƒì„ ëª©ì **ìœ¼ë¡œ í•˜ê³  ìˆìŠµë‹ˆë‹¤. ë¶„ì„ ë°ì´í„°ì…‹ì´ ì–´ë–¤ í˜•íƒœì¸ì§€(e.g. Time Series, Image, NLP, etc.)ì— ë”°ë¼ì„œ ë‹¤ì–‘í•œ ì¢…ë¥˜ì˜ ëª¨ë¸ì„ ì„¤ê³„í•  ìˆ˜ ìˆì§€ë§Œ, ê¸°ë³¸ì ì¸ êµ¬ì¡°ëŠ” ëª¨ë‘ ë™ì¼í•©ë‹ˆë‹¤.   

- **Encoder**: ì£¼ì–´ì§„ Inputì„ ì°¨ì› ì¶•ì†Œë¥¼ í†µí•´ Latent Vector(= Hidden Representation)ë¡œ ë³€í™˜í•˜ëŠ”ë°, ì´ë•Œ ì›ë³¸ ë°ì´í„°ì˜ ì •ë³´ë¥¼ ì˜ ë³´ì¡´í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ ì••ì¶•í•˜ëŠ” ê²ƒì´ Enocderì˜ ëª©ì ì…ë‹ˆë‹¤.   
- **Decoder**: ì¼ì¢…ì˜ Generatorë¡œì„œ, Inputìœ¼ë¡œ ë“¤ì–´ì˜¨ Latent Vectorë¥¼ ì´ìš©í•˜ì—¬ ë‹¤ì‹œ Inputê³¼ ìœ ì‚¬í•˜ê²Œ ë°ì´í„°ë¥¼ ì¬êµ¬ì¶•(Reconstruction)í•˜ëŠ” ì—­í• ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.   
- **Objective Function**: $l(f(x)) = \frac{1}{2}\sum_{k}(\hat{x_k}-x_k)^2$   
    - **ì‹¤ì œ Inputê³¼ ì¬êµ¬ì¶•í•œ Output ê°„ì˜ ì°¨ì´ë¥¼ ìµœì†Œí™” í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ ëª¨ë¸ Parametersê°€ ì—…ë°ì´íŠ¸** ë˜ë„ë¡ í•¨ì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ì¦‰, ì¬êµ¬ì¶•ëœ Output(x')ì™€ Input(x) ê°„ì˜ ì°¨ì´ë¥¼ ì¤„ì´ëŠ” ë°©í–¥ìœ¼ë¡œ í•™ìŠµì´ ì´ë£¨ì–´ì§€ëŠ” ê²ƒì´ì£ .   
    - ì´ë¥¼ **Reconstruction Error**ë¼ê³ ë„ í•©ë‹ˆë‹¤.   

<br/>

**ê·¸ë ‡ë‹¤ë©´ ì–´ë–»ê²Œ ìê¸° ìì‹ ì„ ì…ë ¥ìœ¼ë¡œ ë„£ì–´ ë‹¤ì‹œ ì¬êµ¬ì¶•í•˜ëŠ” ê²ƒì´ ì´ìƒì¹˜ íƒì§€ê°€ ë˜ëŠ” ê±¸ê¹Œìš”?**   
- í•™ìŠµ ì‹œ Normal ë°ì´í„°ë§Œì„ í™œìš©í•œë‹¤ë©´, **AutoEncoderëŠ” Normal ê°’ì„ ê°€ì§€ëŠ” ë°ì´í„°ì˜ ì£¼ìš”í•œ íŠ¹ì§•ë“¤ì„ ì˜ íŒŒì•…í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ í•™ìŠµì´ ì´ë£¨ì–´ì§ˆ ê²ƒ**ì…ë‹ˆë‹¤. ë”°ë¼ì„œ ì œëŒ€ë¡œ í•™ìŠµëœ ëª¨ë¸ì€ ì •ìƒì ì¸ ë°ì´í„°ì— ëŒ€í•´ì„œëŠ” Reconstructionì„ í›Œë¥­í•˜ê²Œ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ê·¸ëŸ¬ë‚˜ ë§Œì¼ Anomaly ë°ì´í„°ê°€ ë“¤ì–´ì˜¨ë‹¤ë©´, í•™ìŠµ ì‹œ í•œ ë²ˆë„ Anomlayë¥¼ ë³´ì§€ ëª»í–ˆë˜ AutoEncoderëŠ” Recosntructionì„ ì˜ ìˆ˜í–‰í•˜ì§€ ëª»í•  ê²ƒì…ë‹ˆë‹¤. ì˜¤ë¡œì§€ **Normalì˜ íŠ¹ì§•ë§Œì„ í•™ìŠµí–ˆê¸° ë•Œë¬¸ì—, ì •ìƒì´ ì•„ë‹Œ íŠ¹ì§•ì„ ê°€ì§„ ë°ì´í„°ì— ëŒ€í•´ì„œëŠ” Reconstructionì— ì–´ë ¤ì›€ì„ ê²ªëŠ” ê²ƒ**ì´ì£ .
- ë”°ë¼ì„œ ìœ„ ëª©ì  í•¨ìˆ˜ì—ì„œ Reconstruction Error ê°’ì´ ì¼ì • ìˆ˜ì¤€(Threshold) ì´ìƒ ë†’ì•„ì§„ë‹¤ë©´, ì´ë¥¼ Anomalyë¼ íŒë‹¨í•  ìˆ˜ ìˆëŠ” ê²ƒì…ë‹ˆë‹¤.
    - ê·¸ë ‡ë‹¤ë©´ ì´ 'Threshold'ëŠ” ì–´ë–»ê²Œ ì •ì˜í•´ì•¼ í• ê°€ìš”? ê·¸ ê¸°ì¤€ì€ ë°ì´í„°ì…‹ë§ˆë‹¤ ê·¸ë¦¬ê³  ë„ë©”ì¸ë§ˆë‹¤ ë‹¤ë¥´ë¯€ë¡œ, ë³¸ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” **ì‹¤í—˜ì„ í†µí•´ ì ì ˆí•œ Thresholdë¥¼ ì •í•˜ëŠ” ê³¼ì •ì„ ì•„ë˜ì— ì†Œê°œ**í•˜ê³ ì í•©ë‹ˆë‹¤.

<br/>

## Data
### Description
ë³¸ íŠœí† ë¦¬ì–¼ì—ì„œ ë‹¤ë£° [ECG5000 Dataset](http://timeseriesclassification.com/description.php?Dataset=ECG5000)ì€ ì‹¬ë¶€ì „ì¦ ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ê¸° ìœ„í•˜ì—¬, ì‚¬ëŒì˜ ì‹¬ì¥ ë°•ë™ì„ ì§€ì†ì ìœ¼ë¡œ ìˆ˜ì§‘í•œ ê²ƒì…ë‹ˆë‹¤. ì´ 5,000ê°œì˜ ECG(ì‹¬ì „ë„) ê´€ì¸¡ì¹˜ë¡œ êµ¬ì„±ë˜ì–´ ìˆìœ¼ë©°, ê° Signalì˜ timestepsì€ 140ì…ë‹ˆë‹¤.   

> __[(ì°¸ê³ )](https://www.heartandstroke.ca/heart-disease/tests/electrocardiogram)__   
> **ECG**: "An electrocardiogram (ECG or EKG) is a test that checks how your heart is functioning by measuring the electrical activity of the heart. With each heart beat, an electrical impulse (or wave) travels through your heart. This wave causes the muscle to squeeze and pump blood from the heart."

ì´ë•Œ ì› ë°ì´í„°ì…‹ì˜ Class(ì‹¬ì¥ ë°•ë™ ì¢…ë¥˜)ëŠ” ì•„ë˜ì™€ ê°™ì´ 5ê°€ì§€ë¡œ êµ¬ë¶„ë©ë‹ˆë‹¤.
| Class | Description | #Instance |
| --- | --- | --- |
| N | Normal | 2919 |
| R-on-T PVC | R-on-T Premature Ventricular Contraction | 1767 |
| PVC | Premature Ventricular Contraction | 194 |
| SP or EB | Supra-ventricular Premature or Ectopic Beat | 96 |
| UB | Unclassified Beat | 24 |

ECGì˜ Normal/Abnormal ì—¬ë¶€ëŠ” ì •ìƒì ì¸ ì‹¬ì¥ ë°•ë™ì¸ì§€, ë¶€ì •ë§¥ê³¼ ê´€ë ¨í•œ ì‹¬ì¥ ë°•ë™ì¸ì§€ë¥¼ êµ¬ë¶„í•˜ëŠ” ê²ƒìœ¼ë¡œ ì •ì˜ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë•Œ Normalì´ ì•„ë‹Œ ClassëŠ” ëª¨ë‘ 4ê°œì´ì§€ë§Œ, 
**ë³¸ íŠœí† ë¦¬ì–¼ì´ Anomaly Detectionì— ëŒ€í•´ ì„¤ëª…í•˜ê³  ìˆë‹¤ëŠ” ì ì„ ê³ ë ¤í•˜ì—¬ì„œ "Unclassified Beat"ë§Œì„ Anomalyë¡œ ì •ì˜**í•©ë‹ˆë‹¤. ì´í›„ Normal(N)ì´ ì•„ë‹Œ Abnormal(UB)ë¥¼ ê²€ì¶œí•  ìˆ˜ ìˆëŠ” ëª¨ë¸ì„ ì„¤ê³„í•´ë³´ê² ìŠµë‹ˆë‹¤.

### Download
[í•´ë‹¹ ë§í¬](http://timeseriesclassification.com/description.php?Dataset=ECG5000)ë¥¼ í†µí•´ì„œ ë°ì´í„°ë¥¼ ë°”ë¡œ ë‹¤ìš´ ë°›ìœ¼ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### Prepare Data and Split Train/Valid/Testset
ë°ì´í„°ë¥¼ ë‹¤ìš´ ë°›ê³  Train/Valid/Testë¥¼ êµ¬ë¶„í•´ë³´ê² ìŠµë‹ˆë‹¤. ì´ë•Œ í•„ìš”í•œ **Hyperparameter**ëŠ” **Train/Validation/Test ê³¼ì •ì—ì„œ í™œìš©í•  Normal ë°ì´í„°ì˜ ë¹„ìœ¨**ì…ë‹ˆë‹¤. ë”ë¶ˆì–´ **Validation ê³¼ì •ì—ì„œ í•„ìš”í•œ Abnormal ë°ì´í„°ì˜ ë¹„ìœ¨** ì—­ì‹œ ì •ì˜í•  í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤. ë³´ë‹¤ ìì„¸í•œ HyperparameterëŠ” [Parameters](#parameters)ì—ì„œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

#### Example of Use
```python
import os, rich, argparse
import numpy as np
import pandas as pd

from sklearn.model_selection import train_test_split

# For visualiation
%matplotlib inline
import matplotlib
import matplotlib.pyplot as plt
import seaborn as sns
sns.set_context("talk")
sns.set_style("white")
sns.set_palette("Pastel1")
plt.rcParams['axes.labelsize'] = 14
plt.rcParams['xtick.labelsize'] = 14
plt.rcParams['ytick.labelsize'] = 14
matplotlib.rc('font', family='Malgun Gothic')  # For Windows
plt.rcParams['axes.unicode_minus'] = False

import warnings
warnings.filterwarnings(action='ignore')


# Load Data
train = pd.read_table(os.path.join(args.data_dir, 'ECG5000_TRAIN.txt'), sep=r'\s{2,}', engine='python', header=None)
test = pd.read_table(os.path.join(args.data_dir, 'ECG5000_TEST.txt'), sep=r'\s{2,}', engine='python', header=None)
```
- ì›ë³¸ ë°ì´í„°ì—ì„œ êµ¬ë¶„ëœ Trainê³¼ Testë¥¼ í•©ì³ í•˜ë‚˜ì˜ Dataframeìœ¼ë¡œ ë§Œë“¤ê² ìŠµë‹ˆë‹¤. ì´ëŠ” AutoEncoderë¥¼ í•™ìŠµí•  ë•Œ ë” ë§ì€ ë°ì´í„°ë¥¼ í™œìš©í•˜ê¸° ìœ„í•¨ì´ë©°, ë°ì´í„°ë¥¼ shuffleí•˜ëŠ” ê³¼ì •ì„ ì¶”ê°€í•©ë‹ˆë‹¤.

```python
# Concatenating
df = pd.concat([train, test])
columns = list(df.columns)
columns[0] = 'Label'
df.columns = columns

# Shuffle
df = df.sample(frac=1.0)

print(df.shape)
df.head()
```
```
(5000, 141)

	Label	1	2	3	4	5	6	7	8	9	...	131	132	133	134	135	136	137	138	139	140
2762	2.0	-0.966898	-2.310166	-2.980837	-3.342557	-3.189898	-3.154114	-2.922813	-2.654268	-2.028948	...	0.540354	0.304268	-0.075843	-0.557498	-1.263778	-1.564023	-2.648592	-3.104930	-3.984882	-2.924599
1159	1.0	2.710067	1.886624	-0.897612	-2.451598	-3.774083	-4.231098	-3.170851	-1.743546	-1.379708	...	-1.214389	-0.702780	0.013427	-0.118604	0.352037	0.583721	0.645176	0.341670	-0.322908	0.419220
1612	1.0	0.707142	-1.658328	-3.381889	-4.027402	-3.948931	-3.620580	-2.773839	-1.689318	-1.529027	...	0.887512	0.902415	1.054119	1.287180	1.303986	1.230156	1.324317	1.733495	2.267364	0.238762
3214	2.0	-0.637958	-1.693304	-2.302505	-2.995992	-3.050792	-2.857468	-2.535753	-2.051791	-1.449830	...	-1.745858	-2.219459	-2.687707	-3.257746	-3.565846	-3.358062	-2.598093	-1.450787	-0.579330	0.513931
542	1.0	-2.016892	-3.123390	-3.679469	-3.768579	-3.431780	-2.651154	-1.848419	-1.682133	-1.362405	...	1.155557	1.198302	1.145470	1.124247	1.143547	1.128024	1.238858	1.567438	1.232474	0.270086
5 rows Ã— 141 columns
```
ì› ë°ì´í„°ì…‹ì€ ì´ 5000ê°œì˜ ê´€ì¸¡ì¹˜ë¥¼ ê°€ì§€ë©°, ê° í–‰ì€ í•˜ë‚˜ì˜ ì‹¬ë°•ìˆ˜ record ì…ë‹ˆë‹¤. ì•ì„œ ë§í–ˆë“¯ì´ ë³¸ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” Abnormal Classë¡œì„œ UB(Unclassifible Beat)ë§Œì„ ì‚¬ìš©í•˜ë¯€ë¡œ, ê°€ìš© ë°ì´í„°ì…‹ì„ êµ¬ì¶•í•˜ê² ìŠµë‹ˆë‹¤.

```python
# Make Dataset
# Abnormal: Unclassified Beat
df = pd.concat([df[df['Label'] == 1], df[df['Label'] == 5]])

print(df.shape)
df.head()
```
```
(2943, 141)
Label	1	2	3	4	5	6	7	8	9	...	131	132	133	134	135	136	137	138	139	140
0	1.0	-0.112522	-2.827204	-3.773897	-4.349751	-4.376041	-3.474986	-2.181408	-1.818286	-1.250522	...	0.160348	0.792168	0.933541	0.796958	0.578621	0.257740	0.228077	0.123431	0.925286	0.193137
1	1.0	-1.100878	-3.996840	-4.285843	-4.506579	-4.022377	-3.234368	-1.566126	-0.992258	-0.754680	...	0.560327	0.538356	0.656881	0.787490	0.724046	0.555784	0.476333	0.773820	1.119621	-1.436250
2	1.0	-0.567088	-2.593450	-3.874230	-4.584095	-4.187449	-3.151462	-1.742940	-1.490659	-1.183580	...	1.284825	0.886073	0.531452	0.311377	-0.021919	-0.713683	-0.532197	0.321097	0.904227	-0.421797
3	1.0	0.490473	-1.914407	-3.616364	-4.318823	-4.268016	-3.881110	-2.993280	-1.671131	-1.333884	...	0.491173	0.350816	0.499111	0.600345	0.842069	0.952074	0.990133	1.086798	1.403011	-0.383564
4	1.0	0.800232	-0.874252	-2.384761	-3.973292	-4.338224	-3.802422	-2.534510	-1.783423	-1.594450	...	0.966606	1.148884	0.958434	1.059025	1.371682	1.277392	0.960304	0.971020	1.614392	1.421456
5 rows Ã— 141 columns
```

### Data EDA
Normal Classì™€ Abnormal Classì˜ ì–‘ìƒì€ ì–´ë–»ê²Œ ë‹¤ë¥¼ê¹Œìš”? ê° Class ë³„ë¡œ í‘œì¤€í™”(smoothed out with one standard deviation on top and bottom of it)ëœ Signalì„ ì‹œê°í™”í•´ë³´ê² ìŠµë‹ˆë‹¤.
```python
def plot_time_series_class(data, class_name, ax, n_steps=10):
    df = pd.DataFrame(data)
    
    smooth_path = df.rolling(n_steps).mean()
    path_deviation = 2 * df.rolling(n_steps).std()

    under_line = (smooth_path - path_deviation)[0]
    over_line = (smooth_path + path_deviation)[0]

    ax.plot(smooth_path, linewidth=2)
    ax.fill_between(
    path_deviation.index,
    under_line,
    over_line,
    alpha=.125
    )
    ax.set_title(class_name, fontsize=20)
    
classes = df.Label.unique()
class_name = ['Normal', 'Abnormal(UB)']

fig, axs = plt.subplots(
  nrows=len(classes) // 3 + 1,
  ncols=3,
  sharey=True,
  figsize=(20, 5)
)

for i, cls in enumerate(classes):
    ax = axs.flat[i]
    data = df[df['Label'] == cls] \
    .drop(labels='Label', axis=1) \
    .mean(axis=0) \
    .to_numpy()
    plot_time_series_class(data, class_name[i], ax)

fig.delaxes(axs.flat[-1])
fig.tight_layout();
```
<p align="center">
    <img src="Anomaly_Detection_Img/EDA.png" width="800"/>
</p>
ì‹œê°í™” ê²°ê³¼, **Normal ë°ì´í„°ëŠ” Abnormalê³¼ ì‹œê°ì ìœ¼ë¡œë„ ëšœë ·í•œ íŒ¨í„´ ì°¨ì´ë¥¼ ë³´ì´ëŠ” ê²ƒì„ í™•ì¸**í•˜ì˜€ìŠµë‹ˆë‹¤. ê·¸ë ‡ë‹¤ë©´ ì´ ë°ì´í„°ì…‹ìœ¼ë¡œ ì´ìƒì¹˜ë¥¼ íƒì§€í•´ë‚¼ ìˆ˜ ìˆì„ê¹Œìš”?

----

# Anomaly Detection PyTorch Implementation
ë°ì´í„°ì…‹ íƒìƒ‰ ê²°ê³¼, ì •ìƒê³¼ ì´ìƒ ê°„ì˜ ëšœë ·í•œ ì°¨ì´ë¥¼ ì‹œê°ì ìœ¼ë¡œ í™•ì¸í•˜ì˜€ìŠµë‹ˆë‹¤. ì´ì œ ë³¸ê²©ì ìœ¼ë¡œ PyTorchë¥¼ ì´ìš©í•˜ì—¬ AutoEncoderë¥¼ êµ¬ì¶•í•˜ê³ , Normal ë°ì´í„°ë§Œì„ í™œìš©í•˜ì—¬ ëª¨ë¸ì„ í•™ìŠµ í›„ ì´ìƒì¹˜ íƒì§€ ê²°ê³¼ë¥¼ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.

## Requirements

## Parameters

## Example of Use

----

# Experiments and Results

### ì‹¤í—˜ 1: Latent Vector ì°¨ì›ì— ë”°ë¥¸ ë³µì› ê°’ ì°¨ì´
-> Bottelneck Layers == Original Data Dimension ì¼ ë•ŒëŠ” ì™œ ì„±ëŠ¥ì´ ì¢‹ì§€ ì•Šì€ì§€ì— ëŒ€í•´ ê¸°ìˆ .

### ì‹¤í—˜ 2: Threshold ë³€í™”ì— ë”°ë¥¸ ì„±ëŠ¥ ì°¨ì´ (https://github.com/cran2367/autoencoder_classifier/blob/master/autoencoder_classifier.ipynb)
-> Threshold ì •í•˜ëŠ” í•¨ìˆ˜
-> F1-Score, Precision, Recall

### ì‹¤í—˜ 3: ì •í•´ì§„ Thresholdë¥¼ ë°”íƒ•ìœ¼ë¡œ, Normalê³¼ Anomalyì˜ ë³µì› ê°’ ì°¨ì´ í™•ì¸
-> ì‹œê°ì ìœ¼ë¡œ í™•ì¸.

### ì‹¤í—˜ 4: Vanilla Dense AutoEncoder ì™¸ì—, ë°ì´í„°ì˜ ì‹œê³„ì—´ì„±ì„ ë°˜ì˜í•˜ëŠ” LSTM/Conv1Dë¡œ Backbone ë°”ê¾¸ì–´ë³´ê¸°
-> ì‹¤í—˜ 2ë¥¼ í†µí•´ Thresholdë¥¼ ì •í•˜ê³ , ì‹¤í—˜ 3ì„ í†µí•´ ë³µì› ê°’ ì°¨ì´ í™•ì¸
-> ì‹¤í—˜ 4ì˜ ê²°ê³¼ë¡œì„œ Vanilla vs. LSTM vs. Conv1D vs. LSTM+Conv1D ê²°ê³¼ ê°ê° ë¹„êµí•´ë³´ê¸° (https://velog.io/@tobigsts1617/4%EC%A3%BC%EC%B0%A8-AutoEncoder-%EA%B8%B0%EB%B0%98-%EC%9D%B4%EC%83%81%EC%B9%98-%ED%83%90%EC%A7%80-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98)
-> ì‹œê°„ ë˜ë©´ Denoising AutoEncoderë„ ê°™ì´.

### ì‹¤í—˜ 5: ì•ì„œ AutoEncderì˜ ì£¼ ëª©ì ì€ Normal ë°ì´í„°ì˜ ì •ë³´ë¥¼ ì˜ ë³´ì¡´í•˜ì—¬ ì••ì¶•í•˜ëŠ” ê²ƒì´ë¼ê³  í•˜ì˜€ìŒ. ê·¸ë ‡ë‹¤ë©´, Latent Variableê³¼ ì›ë³¸ Signal ì‚¬ì´ì˜ ê±°ë¦¬ê°€ ë„ˆë¬´ ë©€ì§€ ì•Šë„ë¡ ê·œì œë¥¼ í•˜ë©´ ì–´ë–¨ê¹Œ? ë‘ ë¶„í¬ ì°¨ì´ë¥¼ KL Divergenceë¥¼ í†µí•´ ê³„ì‚°í•˜ê³ , ì´ ê°’ì´ ë†’ì•„ì§€ì§€ ì•Šë„ë¡ í•˜ë©´ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë‚¼ ìˆ˜ ìˆì„ê¹Œ?

### ì‹¤í—˜ 6: ë‹¤ë¥¸ ë²¤ì¹˜ë§ˆí¬ Time series dataë¥¼ í†µí•œ ì‹¤í—˜ ìˆ˜í–‰. (https://arxiv.org/pdf/1809.10717.pdf)
-> ì‹¤í—˜ 2ë¥¼ í†µí•´ threshold ì •í•˜ê¸°
-> ì‹¤í—˜ 3ì„ í†µí•´ ë³µì› ê°’ ì°¨ì´ í™•ì¸í•˜ê¸°
-> Vanilla / LSTM / LSTM+Conv ê°ê° ì„±ëŠ¥ ì°¨ì´ í™•ì¸í•˜ê¸°
    â””> ì™œ ì´ëŸ° ì„±ëŠ¥ ì°¨ì´ê°€ ë‚¬ì„ì§€ ê³ ë¯¼í•˜ê³  ECGì™€ ê²°ê³¼ ë¹„êµí•˜ê¸° 

-------------
