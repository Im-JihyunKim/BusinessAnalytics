
# 2022 Business Analytics Chapter 3: Anomaly Detection🧐
### Python Tutorial: Anomaly Detection Using AutoEncoder with Time Series Data
### 2022010558 김지현🐲

<br/>

## Table of Contents

------------------

# Anomaly Detection: Overview

## Definition of Anomaly(Novel Data)

<p align="center">
    <img src="Anomaly_Detection_Img/What_is_Anomaly.jpg" width="800"/>
</p>

이번 튜토리얼은 'Anomaly Detection(이상치 탐지)'에 대한 주제로 진행하려 합니다. 그렇다면 '이상치(Anomaly, Novel Data)'란 무엇일까요? 위 사진을 보면, 양상은 다르지만 대부분 호랑이 객체밖에 없는 상황에서 단 하나 용에 대한 객체가 있다면, 이는 일반적인 객체들보다는 조금 다른 특이한 객체가 될 것입니다. 이처럼 __일반적인 데이터와는 다른 조금 특이한 객체를 Anomaly__ 라고 하고, 이를 찾아내는 것이 이상치 탐지의 목적이 됩니다.

보다 학술적으로는, 아래와 같이 '이상치(Anomaly, Novel Data)'를 2가지 관점에서 정의할 수 있습니다.   

1. __데이터 생성 메커니즘__ 에서의 관점: 일반적인 데이터와는 다른 메커니즘에 의해 발생한 데이터    
"Observations that deviate so much from other observations as to arouse suspicions that they were generated by a different mechanism (Hawkins, 1980)"   

2. __데이터 분포에서의 밀도__ 에 대한 관점: 객체들이 발생할 수 있는 확률 밀도가 낮은 데이터   
“Instances that their true probability density is very low (Harmelinget al., 2006)"

<br/>

> __(참고) Anomaly vs. Noise__   
> 이상치 데이터는 노이즈 데이터와는 다릅니다. 노이즈는 데이터 수집 과정에서의 무작위성(Randomness)에 기반하여 자연 발생적으로 들어가는 변동성을 의미하며, 따라서 데이터 분석 시 정확히 가려 지워내는 것이 아니라 데이터에 노이즈가 내재되어 있다는 가정 하에 분석을 진행합니다.   
>
> 반면 이상치는 __분석 과정에서 반드시 찾아내야 하는 "흥미가 있는 객체"__ 라고 이해해야 합니다. 일반적인 데이터를 생성하는 메커니즘을 위배하여 만들어진 데이터이기 때문에, 이를 발견하여 __XAI와 같이 사후적인 분석을 수행해야 할 필요가 있고, 그 객체를 찾아내는 것 자체만으로도 분석에 매우 도움이 되기 때문__ 입니다.   

<br/>

그렇다면 이런 의문이 들 수 있겠죠. 이상치 탐지를 하고 싶을 때, 정상과 이상을 분류해낼 수 있는 Binary Classification 알고리즘을 적용하면 안 되는 걸까요? **왜 우리는 Anomaly Detection이라는 새로운 분야의 알고리즘을 필요로 하는 걸까요?**   

<br/>

## Binary Classification vs. Anomaly Detection
<p align="center">
    <img src="Anomaly_Detection_Img/C_vs_A.jpg" width="800"/>
</p>

전통적인 지도학습(Supervised Learning) 관점에서 Binary Classification은 주어진 데이터를 잘 구분하는 분류 경계면(Decision Boundary)을 잘 찾아내는 것을 목적으로 합니다. 위 그림의 예를 봅시다. 만일 호랑이🐯가 Normal이고 용🐲이 Abnormal 데이터라고 한다면, **Binary Classifier**는 **새로운 데이터 "A"를** 무엇으로 판단할까요? Normal Class의 경계면 안쪽에 속해있기 때문에 **Normal이라고 판단**할 것입니다.    

이때 우리는 이러한 질문을 던질 수 있습니다. **Abnormal🐲 관측치가 절대적으로 적은 상황에서, 해당 데이터가 Abnormal Class를 대표할 수 있는가?"** 에 대해 말입니다. 
왜냐하면 적은 관측치를 바탕으로 생성된 분류 경계면을 온전히 신뢰할 수 없기 때문이죠. 생각해보니 새로운 데이터 "A"는 'Normal'이라고 판단하기에는 다른 정상 관측치들(🐯)과는 Feature Space 상의 거리가 꽤 먼 것을 볼 수 있습니다.  
 
바로 이러한 문제를 바탕으로, Anomaly Detection은 **Normal 데이터는 충분히 많으니, "정상"이란 무엇인가를 정의하여 이에 포함되지 않는 것을 걸러내보자**는 아이디어에서 출발하게 됩니다. 이러한 관점에서 **새로운 데이터 "A"** 는 Anomaly Detection의 관점에서는 **Normal이 아닌 것**으로 재정의되겠죠.   

> **(참고)**   
> Normal이 아니라고 해서 데이터가 반드시 "Abnormal"인 것은 아닙니다. 하지만 현 관측치를 기준으로 보았을 때 해당 데이터는 우리가 규정한 "Normal"이라 하기에는 어려움이 있습니다. 이러한 접근법이 유효한 이유는 "Abnormal"의 종류가 2가지일 때입니다. 가용할 수 있는 불량 관측치가 하나의 유형(이를테면 🐲)밖에 없는 상황에서, 한 번도 관측되지 못했던 새로운 불량 유형(이를테면 🦁)을 발견할 수 있다는 이점을 가지기 때문입니다.
> 
> 이처럼 Classification은 데이터를 반드시 주어진 범주 중 하나로 할당하지만, Anomaly Detection은 정상의 Boundary를 정하고 '정상' '정상이 아님'으로 보다 광범위한 분류가 가능하다는 측면에서 둘은 차이를 가집니다. 즉, Anomaly Detection은 일반적인 데이터의 범주와 확연히 구분되는 다른 양상의 데이터를 찾는 것이죠. 이러한 관점에서 Anomaly Detection을 통해 찾아낸 데이터는 불량, 오류, 악성코드, 가짜 데이터일 수도 있지만, 예외, 새로운 패턴 등의 데이터일 수도 있습니다.

<br/>

## Assumption of Anomaly Detection
이상치 데이터의 기본 가정은 **정상 데이터가 정상이 아닌 데이터보다 훨씬 더 많다**(There are considerably more "normal" observations than abnormal observations in the data)입니다. 그리고 모델링 시에는 **오로지 정상 데이터만을 활용하여 모델을 학습**시킨 후, 정상 범위를 정의하여 이상을 탐지해낸다는 가정을 기저로 활용하고 있습니다.   

<br/>

-------

# Dive into Anomaly Detection Using AutoEncoder with Time Series Data
이러한 점을 바탕으로, 본 튜토리얼에서는 Anomaly Detection에 대해서, 그 중에서도 딥러닝 모델을 바탕으로 수행되는 **AutoEncoder Based Anomaly Detection**에 대한 간략한 소개 및 활용 방안에 대해 소개해보고자 합니다. 이때 **딥러닝 기법을 활용한 모델 기반의 Anomaly Detection을 소개하는 이유는, 데이터가 내포하는 정보를 최대한 활용하는 동시에 구조를 유연하게 바꾸어가며 모델 성능을 높일 수 있는 장점을 가지기 때문**입니다. 따라서 모델을 학습시킬 만큼의 충분한 데이터가 있다면 본 튜토리얼을 통해 딥러닝, 그 중에서도 AutoEncoder를 이용한 Anomaly Detection의 기본을 알아갈 수 있을 것입니다.

특히 본 튜토리얼에서는 **시계열 데이터에 있어 이상 탐지에 대한 튜토리얼**을 작성하고자 하며, 활용하고자 하는 데이터는 **Real-World Time Series Dataset 중 Electrocardiogram(ECG) 심전도 데이터셋**입니다. 

## AutoEncoder
<p align="center">
    <img src="Anomaly_Detection_Img/AE.png" width="800"/>
</p>

AutoEncoder는 통상적으로 위와 같은 구조를 가지는 모델로, **입력과 출력이 동일한 인공 신경망 구조**를 바탕으로 **입력으로 받은 데이터(x)를 출력으로 최대한 가깝게 재구축(x')하는 것을 목적**으로 하고 있습니다. 분석 데이터셋이 어떤 형태인지(e.g. Time Series, Image, NLP, etc.)에 따라서 다양한 종류의 모델을 설계할 수 있지만, 기본적인 구조는 모두 동일합니다.   

- **Encoder**: 주어진 Input을 차원 축소를 통해 Latent Vector(= Hidden Representation)로 변환하는데, 이때 원본 데이터의 정보를 잘 보존하는 방향으로 압축하는 것이 Enocder의 목적입니다.   
- **Decoder**: 일종의 Generator로서, Input으로 들어온 Latent Vector를 이용하여 다시 Input과 유사하게 데이터를 재구축(Reconstruction)하는 역할을 수행합니다.   
- **Objective Function**: $l(f(x)) = \frac{1}{2}\sum_{k}(\hat{x_k}-x_k)^2$   
    - **실제 Input과 재구축한 Output 간의 차이를 최소화 하는 방향으로 모델 Parameters가 업데이트** 되도록 함을 의미합니다. 즉, 재구축된 Output(x')와 Input(x) 간의 차이를 줄이는 방향으로 학습이 이루어지는 것이죠.   
    - 이를 **Reconstruction Error**라고도 합니다.   

<br/>

**그렇다면 어떻게 자기 자신을 입력으로 넣어 다시 재구축하는 것이 이상치 탐지가 되는 걸까요?**   
- 학습 시 Normal 데이터만을 활용한다면, **AutoEncoder는 Normal 값을 가지는 데이터의 주요한 특징들을 잘 파악하는 방향으로 학습이 이루어질 것**입니다. 따라서 제대로 학습된 모델은 정상적인 데이터에 대해서는 Reconstruction을 훌륭하게 수행할 수 있습니다.
- 그러나 만일 Anomaly 데이터가 들어온다면, 학습 시 한 번도 Anomlay를 보지 못했던 AutoEncoder는 Recosntruction을 잘 수행하지 못할 것입니다. 오로지 **Normal의 특징만을 학습했기 때문에, 정상이 아닌 특징을 가진 데이터에 대해서는 Reconstruction에 어려움을 겪는 것**이죠.
- 따라서 위 목적 함수에서 Reconstruction Error 값이 일정 수준(Threshold) 이상 높아진다면, 이를 Anomaly라 판단할 수 있는 것입니다.
    - 그렇다면 이 'Threshold'는 어떻게 정의해야 할가요? 그 기준은 데이터셋마다 그리고 도메인마다 다르므로, 본 튜토리얼에서는 **실험을 통해 적절한 Threshold를 정하는 과정을 아래에 소개**하고자 합니다.

<br/>

## Data
### Description
본 튜토리얼에서 다룰 [ECG5000 Dataset](http://timeseriesclassification.com/description.php?Dataset=ECG5000)은 심부전증 여부를 판단하기 위하여, 사람의 심장 박동을 지속적으로 수집한 것입니다. 총 5,000개의 ECG(심전도) 관측치로 구성되어 있으며, 각 Signal의 timesteps은 140입니다.   

> __[(참고)](https://www.heartandstroke.ca/heart-disease/tests/electrocardiogram)__   
> **ECG**: "An electrocardiogram (ECG or EKG) is a test that checks how your heart is functioning by measuring the electrical activity of the heart. With each heart beat, an electrical impulse (or wave) travels through your heart. This wave causes the muscle to squeeze and pump blood from the heart."

이때 원 데이터셋의 Class(심장 박동 종류)는 아래와 같이 5가지로 구분됩니다.
| Class | Description | #Instance |
| --- | --- | --- |
| N | Normal | 2919 |
| R-on-T PVC | R-on-T Premature Ventricular Contraction | 1767 |
| PVC | Premature Ventricular Contraction | 194 |
| SP or EB | Supra-ventricular Premature or Ectopic Beat | 96 |
| UB | Unclassified Beat | 24 |

ECG의 Normal/Abnormal 여부는 정상적인 심장 박동인지, 부정맥과 관련한 심장 박동인지를 구분하는 것으로 정의될 수 있습니다. 이때 Normal이 아닌 Class는 모두 4개이지만, 
**본 튜토리얼이 Anomaly Detection에 대해 설명하고 있다는 점을 고려하여서 "Unclassified Beat"만을 Anomaly로 정의**합니다. 이후 Normal(N)이 아닌 Abnormal(UB)를 검출할 수 있는 모델을 설계해보겠습니다.

### Download
[해당 링크](http://timeseriesclassification.com/description.php?Dataset=ECG5000)를 통해서 데이터를 바로 다운 받으실 수 있습니다.

### Prepare Data and Split Train/Valid/Testset
데이터를 다운 받고 Train/Valid/Test를 구분해보겠습니다. 이때 필요한 **Hyperparameter**는 **Train/Validation/Test 과정에서 활용할 Normal 데이터의 비율**입니다. 더불어 **Validation 과정에서 필요한 Abnormal 데이터의 비율** 역시 정의할 필요가 있습니다. 보다 자세한 Hyperparameter는 [Parameters](#parameters)에서 확인하실 수 있습니다.

#### Example of Use
```python
import os, rich, argparse
import numpy as np
import pandas as pd

from sklearn.model_selection import train_test_split

# For visualiation
%matplotlib inline
import matplotlib
import matplotlib.pyplot as plt
import seaborn as sns
sns.set_context("talk")
sns.set_style("white")
sns.set_palette("Pastel1")
plt.rcParams['axes.labelsize'] = 14
plt.rcParams['xtick.labelsize'] = 14
plt.rcParams['ytick.labelsize'] = 14
matplotlib.rc('font', family='Malgun Gothic')  # For Windows
plt.rcParams['axes.unicode_minus'] = False

import warnings
warnings.filterwarnings(action='ignore')


# Load Data
train = pd.read_table(os.path.join(args.data_dir, 'ECG5000_TRAIN.txt'), sep=r'\s{2,}', engine='python', header=None)
test = pd.read_table(os.path.join(args.data_dir, 'ECG5000_TEST.txt'), sep=r'\s{2,}', engine='python', header=None)
```
- 원본 데이터에서 구분된 Train과 Test를 합쳐 하나의 Dataframe으로 만들겠습니다. 이는 AutoEncoder를 학습할 때 더 많은 데이터를 활용하기 위함이며, 데이터를 shuffle하는 과정을 추가합니다.

```python
# Concatenating
df = pd.concat([train, test])
columns = list(df.columns)
columns[0] = 'Label'
df.columns = columns

# Shuffle
df = df.sample(frac=1.0)

print(df.shape)
df.head()
```
```
(5000, 141)

	Label	1	2	3	4	5	6	7	8	9	...	131	132	133	134	135	136	137	138	139	140
2762	2.0	-0.966898	-2.310166	-2.980837	-3.342557	-3.189898	-3.154114	-2.922813	-2.654268	-2.028948	...	0.540354	0.304268	-0.075843	-0.557498	-1.263778	-1.564023	-2.648592	-3.104930	-3.984882	-2.924599
1159	1.0	2.710067	1.886624	-0.897612	-2.451598	-3.774083	-4.231098	-3.170851	-1.743546	-1.379708	...	-1.214389	-0.702780	0.013427	-0.118604	0.352037	0.583721	0.645176	0.341670	-0.322908	0.419220
1612	1.0	0.707142	-1.658328	-3.381889	-4.027402	-3.948931	-3.620580	-2.773839	-1.689318	-1.529027	...	0.887512	0.902415	1.054119	1.287180	1.303986	1.230156	1.324317	1.733495	2.267364	0.238762
3214	2.0	-0.637958	-1.693304	-2.302505	-2.995992	-3.050792	-2.857468	-2.535753	-2.051791	-1.449830	...	-1.745858	-2.219459	-2.687707	-3.257746	-3.565846	-3.358062	-2.598093	-1.450787	-0.579330	0.513931
542	1.0	-2.016892	-3.123390	-3.679469	-3.768579	-3.431780	-2.651154	-1.848419	-1.682133	-1.362405	...	1.155557	1.198302	1.145470	1.124247	1.143547	1.128024	1.238858	1.567438	1.232474	0.270086
5 rows × 141 columns
```
원 데이터셋은 총 5000개의 관측치를 가지며, 각 행은 하나의 심박수 record 입니다. 앞서 말했듯이 본 튜토리얼에서는 Abnormal Class로서 UB(Unclassifible Beat)만을 사용하므로, 가용 데이터셋을 구축하겠습니다.

```python
# Make Dataset
# Abnormal: Unclassified Beat
df = pd.concat([df[df['Label'] == 1], df[df['Label'] == 5]])

print(df.shape)
df.head()
```
```
(2943, 141)
Label	1	2	3	4	5	6	7	8	9	...	131	132	133	134	135	136	137	138	139	140
0	1.0	-0.112522	-2.827204	-3.773897	-4.349751	-4.376041	-3.474986	-2.181408	-1.818286	-1.250522	...	0.160348	0.792168	0.933541	0.796958	0.578621	0.257740	0.228077	0.123431	0.925286	0.193137
1	1.0	-1.100878	-3.996840	-4.285843	-4.506579	-4.022377	-3.234368	-1.566126	-0.992258	-0.754680	...	0.560327	0.538356	0.656881	0.787490	0.724046	0.555784	0.476333	0.773820	1.119621	-1.436250
2	1.0	-0.567088	-2.593450	-3.874230	-4.584095	-4.187449	-3.151462	-1.742940	-1.490659	-1.183580	...	1.284825	0.886073	0.531452	0.311377	-0.021919	-0.713683	-0.532197	0.321097	0.904227	-0.421797
3	1.0	0.490473	-1.914407	-3.616364	-4.318823	-4.268016	-3.881110	-2.993280	-1.671131	-1.333884	...	0.491173	0.350816	0.499111	0.600345	0.842069	0.952074	0.990133	1.086798	1.403011	-0.383564
4	1.0	0.800232	-0.874252	-2.384761	-3.973292	-4.338224	-3.802422	-2.534510	-1.783423	-1.594450	...	0.966606	1.148884	0.958434	1.059025	1.371682	1.277392	0.960304	0.971020	1.614392	1.421456
5 rows × 141 columns
```

### Data EDA
Normal Class와 Abnormal Class의 양상은 어떻게 다를까요? 각 Class 별로 표준화(smoothed out with one standard deviation on top and bottom of it)된 Signal을 시각화해보겠습니다.
```python
def plot_time_series_class(data, class_name, ax, n_steps=10):
    df = pd.DataFrame(data)
    
    smooth_path = df.rolling(n_steps).mean()
    path_deviation = 2 * df.rolling(n_steps).std()

    under_line = (smooth_path - path_deviation)[0]
    over_line = (smooth_path + path_deviation)[0]

    ax.plot(smooth_path, linewidth=2)
    ax.fill_between(
    path_deviation.index,
    under_line,
    over_line,
    alpha=.125
    )
    ax.set_title(class_name, fontsize=20)
    
classes = df.Label.unique()
class_name = ['Normal', 'Abnormal(UB)']

fig, axs = plt.subplots(
  nrows=len(classes) // 3 + 1,
  ncols=3,
  sharey=True,
  figsize=(20, 5)
)

for i, cls in enumerate(classes):
    ax = axs.flat[i]
    data = df[df['Label'] == cls] \
    .drop(labels='Label', axis=1) \
    .mean(axis=0) \
    .to_numpy()
    plot_time_series_class(data, class_name[i], ax)

fig.delaxes(axs.flat[-1])
fig.tight_layout();
```
<p align="center">
    <img src="Anomaly_Detection_Img/EDA.png" width="800"/>
</p>
시각화 결과, **Normal 데이터는 Abnormal과 시각적으로도 뚜렷한 패턴 차이를 보이는 것을 확인**하였습니다. 그렇다면 이 데이터셋으로 이상치를 탐지해낼 수 있을까요?

----

# Anomaly Detection PyTorch Implementation
데이터셋 탐색 결과, 정상과 이상 간의 뚜렷한 차이를 시각적으로 확인하였습니다. 이제 본격적으로 PyTorch를 이용하여 AutoEncoder를 구축하고, Normal 데이터만을 활용하여 모델을 학습 후 이상치 탐지 결과를 알아보겠습니다.

## Requirements

## Parameters

## Example of Use

----

# Experiments and Results

### 실험 1: Latent Vector 차원에 따른 복원 값 차이
-> Bottelneck Layers == Original Data Dimension 일 때는 왜 성능이 좋지 않은지에 대해 기술.

### 실험 2: Threshold 변화에 따른 성능 차이 (https://github.com/cran2367/autoencoder_classifier/blob/master/autoencoder_classifier.ipynb)
-> Threshold 정하는 함수
-> F1-Score, Precision, Recall

### 실험 3: 정해진 Threshold를 바탕으로, Normal과 Anomaly의 복원 값 차이 확인
-> 시각적으로 확인.

### 실험 4: Vanilla Dense AutoEncoder 외에, 데이터의 시계열성을 반영하는 LSTM/Conv1D로 Backbone 바꾸어보기
-> 실험 2를 통해 Threshold를 정하고, 실험 3을 통해 복원 값 차이 확인
-> 실험 4의 결과로서 Vanilla vs. LSTM vs. Conv1D vs. LSTM+Conv1D 결과 각각 비교해보기 (https://velog.io/@tobigsts1617/4%EC%A3%BC%EC%B0%A8-AutoEncoder-%EA%B8%B0%EB%B0%98-%EC%9D%B4%EC%83%81%EC%B9%98-%ED%83%90%EC%A7%80-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98)
-> 시간 되면 Denoising AutoEncoder도 같이.

### 실험 5: 앞서 AutoEncder의 주 목적은 Normal 데이터의 정보를 잘 보존하여 압축하는 것이라고 하였음. 그렇다면, Latent Variable과 원본 Signal 사이의 거리가 너무 멀지 않도록 규제를 하면 어떨까? 두 분포 차이를 KL Divergence를 통해 계산하고, 이 값이 높아지지 않도록 하면 더 좋은 성능을 낼 수 있을까?

### 실험 6: 다른 벤치마크 Time series data를 통한 실험 수행. (https://arxiv.org/pdf/1809.10717.pdf)
-> 실험 2를 통해 threshold 정하기
-> 실험 3을 통해 복원 값 차이 확인하기
-> Vanilla / LSTM / LSTM+Conv 각각 성능 차이 확인하기
    └> 왜 이런 성능 차이가 났을지 고민하고 ECG와 결과 비교하기 

-------------
